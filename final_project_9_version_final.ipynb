{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corporate-defensive",
   "metadata": {
    "id": "corporate-defensive"
   },
   "source": [
    "# Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-sessions",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1622683405896,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "contemporary-sessions",
    "outputId": "660dc373-a88a-4d17-f0f5-8a0ebe317fdc"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# data viz libraries\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\") # to make charts look better\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for functions\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for ML\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import plotly modules\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# make it work on jupyter notebook\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# use Plotly locally\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-covering",
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1622683406841,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "backed-covering"
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "dataFeatures = pd.read_csv(\"C:/Users/digit/Desktop/Ironhack/project-week-9-final-project/data/features.csv\")\n",
    "dataStores = pd.read_csv(\"C:/Users/digit/Desktop/Ironhack/project-week-9-final-project/data/stores.csv\")\n",
    "dataTest = pd.read_csv(\"C:/Users/digit/Desktop/Ironhack/project-week-9-final-project/data/test.csv\")\n",
    "dataTrain = pd.read_csv(\"C:/Users/digit/Desktop/Ironhack/project-week-9-final-project/data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-memorial",
   "metadata": {
    "id": "regulated-memorial"
   },
   "source": [
    "# EDA and Data Cleaning\n",
    "\n",
    "- Here we will explore the data in order to search for patterns, relationships and to understand the data better. \n",
    "- Perform data cleaning if neccessary and data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-mountain",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1622683406851,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "russian-mountain",
    "outputId": "bd1a01b5-433e-410e-a6c7-1a93d4b209ea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataStores.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-rescue",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1622683406854,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "bacterial-rescue",
    "outputId": "9896fef7-0bd9-487c-8702-aad3a156ed09"
   },
   "outputs": [],
   "source": [
    "dataStores.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-aviation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1622683406856,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "weird-aviation",
    "outputId": "a237e5bf-2b97-48e9-b532-4f1bcf4752c8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFeatures.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-antibody",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1622683406857,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "canadian-antibody",
    "outputId": "3e4b4042-afd6-4bef-9205-ac036220aeea"
   },
   "outputs": [],
   "source": [
    "dataFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-spine",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1622683406858,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "driving-spine",
    "outputId": "b61033c3-105a-4643-fc19-174b35050a5a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we will start by merging dataStores and dataFeatures since Features is the extension of Stores\n",
    "FeatSto = dataFeatures.merge(dataStores, how=\"inner\", on=\"Store\")\n",
    "\n",
    "# check the head of the new df\n",
    "FeatSto.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-small",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1622683406859,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "chicken-small",
    "outputId": "50df074d-031d-4d4a-ff96-bcbaaad3a102"
   },
   "outputs": [],
   "source": [
    "FeatSto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-geneva",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1622683406860,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "mediterranean-geneva",
    "outputId": "f748de24-a2a7-4c6b-f7d5-349d3b31da15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the dtypes in FeatSto\n",
    "\n",
    "FeatSto.dtypes\n",
    "\n",
    "# Type is of categorical nature\n",
    "# IsHoliday of binary categorical nature \n",
    "\n",
    "# the rest are numerical (Store and Size of discrete type, and the rest of continous type)\n",
    "# some of the features might contain numerical values but still behave as categorical\n",
    "# Date is string and we will convert it into datetime later or drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-ordinary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1622683407265,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "reported-ordinary",
    "outputId": "a1294dd3-b531-497d-817b-894a4983023b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "FeatSto.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-monkey",
   "metadata": {
    "id": "flexible-monkey"
   },
   "source": [
    "## Inspect the train and test data (dataTrain and dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-bosnia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1622683407268,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "likely-bosnia",
    "outputId": "5581bae8-e501-4357-bd2d-75442bff8e4f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-forwarding",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1622683407270,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "massive-forwarding",
    "outputId": "0c782de2-af1f-4d5b-a477-730491bcf4db"
   },
   "outputs": [],
   "source": [
    "dataTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-staff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1622683407271,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "natural-staff",
    "outputId": "e93bd00a-1288-4b7e-e18c-64c82cf4444c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as we can see  dataTrain includes additional Weekly_Sales\n",
    "dataTrain.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-biodiversity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1622683407272,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "national-biodiversity",
    "outputId": "c44a3293-67fe-401f-d102-18ae7d2fc03c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-piano",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1622683407273,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "declared-piano",
    "outputId": "5c20e880-5a5c-4f42-8dc3-9dc316610dba"
   },
   "outputs": [],
   "source": [
    "dataTest.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-uniform",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1622683407273,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "automated-uniform",
    "outputId": "c708273e-9b7b-4cf4-f0c6-b6f0f171fa53",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTrain.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-immune",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1622683407274,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "wooden-immune",
    "outputId": "49f8dc97-19ab-44b2-f255-3bd789f8249d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we will disregard the dataTest and use only dataTrain\n",
    "# (we will train-test split the data later)\n",
    "# merge dataTrain with Featsto ->dfwTrain\n",
    "# now we have a dataframe containing dataTrain\n",
    "# FeatSto with dataTrain\n",
    "\n",
    "dfwTrain = pd.merge(FeatSto, dataTrain, how=\"inner\", on=[\"Store\", \"Date\", \"IsHoliday\"])\n",
    "\n",
    "dfwTrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-professor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1622683407275,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "revolutionary-professor",
    "outputId": "e0140af2-89cf-4bcb-b6da-9488e19d578a"
   },
   "outputs": [],
   "source": [
    "dfwTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-metallic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1622683407660,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "outstanding-metallic",
    "outputId": "c6e34711-a5b1-4c3b-a026-4b0276d36e42",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfwTrain.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-buddy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1622683407662,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "based-buddy",
    "outputId": "eaf93086-8eab-475b-b4f2-a743f8c06bd0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rename dfwTrain into df_total\n",
    "\n",
    "df_total = dfwTrain\n",
    "\n",
    "# show the head of the total dataframe\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-furniture",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1622683407663,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "spare-furniture",
    "outputId": "60039e2a-7206-4922-b17e-d01c9feb85e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the tail\n",
    "\n",
    "df_total.tail()\n",
    "\n",
    "# first impression:\n",
    "# Date is the week\n",
    "# Markdowns 1 - 5 contain a lot of missing values\n",
    "# Weekly_Sales is numerical continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-neighborhood",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1622683407664,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "removed-neighborhood",
    "outputId": "16dd6950-9322-42db-c570-c31cbd68f58f"
   },
   "outputs": [],
   "source": [
    "# check the shape of df_total\n",
    "\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-handy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1622683407665,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "extreme-handy",
    "outputId": "fb5f8993-84c0-41f0-ca7e-335e2c973420"
   },
   "outputs": [],
   "source": [
    "# check the dtypes of df_total\n",
    "\n",
    "df_total.dtypes\n",
    "\n",
    "# most features have numerical values\n",
    "# Date, Type is a string\n",
    "# some features with numerical values might behave as categoricals, encode them later\n",
    "# such as Type, IsHoliday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-value",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1622683407666,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "hundred-value",
    "outputId": "c2efae95-df1a-41c8-d154-3eb4f37bbd43"
   },
   "outputs": [],
   "source": [
    "# now we can check for missing values\n",
    "\n",
    "df_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-paragraph",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1622683407667,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "parental-paragraph",
    "outputId": "36c1e827-24de-4d6e-fa35-6c2e04e4cfbd"
   },
   "outputs": [],
   "source": [
    "# calculate the percentage of missing values in each column\n",
    "\n",
    "df_total.isnull().sum() / len(df_total)\n",
    "\n",
    "# if the column contains 85% missing values then it should be dropped\n",
    "# MarkDown1-5 contains anonymized data and lots of missing values, despite that, they contain important data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-companion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1622683408069,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "alike-companion",
    "outputId": "4ae2b145-190e-4461-87dc-53789e6185c9"
   },
   "outputs": [],
   "source": [
    "# instead of dropping, we will fill the NaN values with zero values\n",
    "# because the code was executed the first time, when we execute it again, it will show an error\n",
    "df_total.fillna(0, inplace=True)\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-selection",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1622683408071,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "satisfactory-selection",
    "outputId": "42dc7f16-fd88-40df-e264-775b8b50244b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values again\n",
    "\n",
    "df_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-journal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1622683408072,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "enclosed-journal",
    "outputId": "34c9a86a-f7a5-4557-92cf-1749bdeac204"
   },
   "outputs": [],
   "source": [
    "# check for duplicated values\n",
    "\n",
    "df_total.duplicated().sum()\n",
    "\n",
    "# no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-canal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1622683408346,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "demanding-canal",
    "outputId": "35ac18cf-a7cc-4fbc-c477-6409fdb260a0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add a Month column\n",
    "\n",
    "df_total[\"Month\"] = pd.to_datetime(df_total['Date']).dt.month\n",
    "df_total.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-thomas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1622683408348,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "average-thomas",
    "outputId": "9a360fa1-16af-4366-bfea-75736c82279d"
   },
   "outputs": [],
   "source": [
    "# add a Week column \n",
    "df_total[\"Week\"] = pd.to_datetime(df_total[\"Date\"]).dt.week\n",
    "df_total.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-nickel",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1622683408731,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "computational-nickel",
    "outputId": "2489d02a-84b3-4c27-db11-fa4b197ecec5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add Year column\n",
    "df_total[\"Year\"] = pd.to_datetime(df_total[\"Date\"]).dt.year \n",
    "df_total.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-lodge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1622683408732,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "charged-lodge",
    "outputId": "9a6d52a1-e1ed-4f9d-8e00-885adba12cde",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert \"Date\" column to datetime format\n",
    "df_total[\"Date\"] = pd.to_datetime(df_total[\"Date\"])\n",
    "df_total.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-kinase",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1622683408733,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "surface-kinase",
    "outputId": "316c63ba-0c32-4937-fade-f6417972ad0c"
   },
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-forest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "executionInfo": {
     "elapsed": 1175,
     "status": "ok",
     "timestamp": 1622683409895,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "federal-forest",
    "outputId": "051d7420-9622-43e3-9d21-6e5fa172e962",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot Average Monthly Sales - Per Year\n",
    "\n",
    "weekly_sales_2010 = df_total[df_total.Year==2010]['Weekly_Sales'].groupby(df_total['Month']).mean()\n",
    "weekly_sales_2011 = df_total[df_total.Year==2011]['Weekly_Sales'].groupby(df_total['Month']).mean()\n",
    "weekly_sales_2012 = df_total[df_total.Year==2012]['Weekly_Sales'].groupby(df_total['Month']).mean()\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.lineplot(weekly_sales_2010.index, weekly_sales_2010.values)\n",
    "sns.lineplot(weekly_sales_2011.index, weekly_sales_2011.values)\n",
    "sns.lineplot(weekly_sales_2012.index, weekly_sales_2012.values)\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(1, 13, step=1))\n",
    "plt.legend(['2010', '2011', '2012'], loc='best', fontsize=16)\n",
    "plt.title('Average Monthly Sales - Per Year', fontsize=18)\n",
    "plt.ylabel('Sales', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 2012 compared to the rest was not doing so well\n",
    "\n",
    "# there is a sharp rise in Sales between January and February, which is connected to SuperBowl\n",
    "# and as we can see, the Monthly Sales are usually spiking in November and December\n",
    "# when Thanksgiving and Christmas are happening\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-transmission",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 33177,
     "status": "ok",
     "timestamp": 1622683443054,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "statistical-transmission",
    "outputId": "32a12ea8-f525-4b0d-f3d5-dd1a462256f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use Plotly to plot TimeSeries to see whether Date affects Weekly_Sales\n",
    "# make one plot\n",
    "\n",
    "px.line(df_total, x=\"Date\", y=\"Weekly_Sales\", labels={\"x\":\"Date\", \"y\":\"Weekly_Sales\"},\n",
    "       title=\"Weekly Sales across Feb 2010 - Oct 2012\")\n",
    "\n",
    "# in more detail, we can see how Date affects Weekly Sales\n",
    "# the highest spikes are on Thanksgiving Day and Christmas Day\n",
    "# as we have seen in the previous plot, 2012 was not so good in terms of sales for Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"Size\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Plotly to plot a 3-dimensional lineplot\n",
    "# we want to see whether Size has any impact on Weekly Sales\n",
    "fig = px.line_3d(df_total, x='Year', y='Weekly_Sales', z='Size', color='Year')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-presentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot Average Weekly Sales per Store\n",
    "\n",
    "weekly_sales = df_total[\"Weekly_Sales\"].groupby(df_total[\"Store\"]).mean()\n",
    "fig = px.bar(weekly_sales, y=\"Weekly_Sales\", labels={'Weekly_Sales':'Average Weekly Sales'}, title = \"Average Weekly Sales per Store\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Average Weekly Sales per Department\n",
    "weekly_sales = df_total[\"Weekly_Sales\"].groupby(df_total[\"Dept\"]).mean()\n",
    "fig = px.bar(weekly_sales, y=\"Weekly_Sales\", labels={'Weekly_Sales':'Average Weekly Sales'}, title = \"Average Weekly Sales per Department\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-aviation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1622683443065,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "musical-aviation",
    "outputId": "9a50c7b1-22dc-42b8-ad37-9545d39797a1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now we can drop Date column now\n",
    "\n",
    "df_total.drop([\"Date\"], inplace=True, axis=1)\n",
    "df_total.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-injection",
   "metadata": {
    "id": "electronic-injection"
   },
   "source": [
    "#### Encode categorical features\n",
    "\n",
    "For Linear Regression, we need to have numerical values. Thus we will encode the categorical features from the dataset into numerical values.\n",
    "\n",
    "Since it's of categorical text data. We use Label Encoder to convert them into model-understandable numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-local",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1622683443066,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "fifteen-local"
   },
   "outputs": [],
   "source": [
    "# encode Type\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "  \n",
    "le = LabelEncoder()\n",
    "df_total['Type']= le.fit_transform(df_total['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-entertainment",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1622683443066,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "lasting-entertainment"
   },
   "outputs": [],
   "source": [
    "# encode IsHoliday\n",
    "\n",
    "df_total['IsHoliday'] = le.fit_transform(df_total['IsHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-array",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1622683443067,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "engaging-array",
    "outputId": "f221c154-f5d5-49c3-f066-1427b68c1816"
   },
   "outputs": [],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-proportion",
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1622683443068,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "boring-proportion",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# took a sample with the size of 5000, which should be enough to better understand the relationship between the columns\n",
    "\n",
    "# had problems with loading the plot, that's why I saved an image of it\n",
    "\n",
    "# sns.pairplot(df_total.sample(5000), size = 5)\n",
    "\n",
    "#from IPython.display import Image\n",
    "#Image(\"sns_pairplot_df_total.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-tuesday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1622683443070,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "upset-tuesday",
    "outputId": "5e6309b1-fb4b-401b-fae6-6bbdcc8f79b0"
   },
   "outputs": [],
   "source": [
    "# plot a scatter matrix in plotly (because sns.pairplot was too heavy)\n",
    "\n",
    "fig = px.scatter_matrix(df_total.sample(1000), dimensions=['Store', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
    "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
    "       'IsHoliday', 'Type', 'Size', 'Dept', 'Weekly_Sales', 'Month', 'Week',\n",
    "       'Year'], height=5000, width=5000, title=\"Scatter Matrix\", size_max=20)\n",
    "fig.show()\n",
    "\n",
    "# no correlation between features mostly\n",
    "# we can drop Type later\n",
    "# we can drop Size later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-equation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1622683443070,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "lasting-equation",
    "outputId": "2c80d03a-7c28-4443-87cd-240c3c887534"
   },
   "outputs": [],
   "source": [
    "# check for correlations with correlation matrix\n",
    "corr_matrix = df_total.corr(method=\"pearson\") # we chose 'pearson'\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-chocolate",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1622683443071,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "lyric-chocolate",
    "outputId": "2d4ee498-22e5-4af7-edc1-700d5c9b1f25",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot a heatmap for better understanding of correlation\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n",
    "\n",
    "# values range between (-1,1)\n",
    "# 0: no correlation at all\n",
    "# 0 - 0.3: weak correlation\n",
    "# 0.3 - 0.7: moderate correlation\n",
    "# 0.7 - 1: strong correlation\n",
    "\n",
    "# strong correlation between MarkDown1 and MarkDown4, drop MarkDown4 later\n",
    "# Year and Fuel_Price show high correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-mining",
   "metadata": {
    "id": "increasing-mining"
   },
   "source": [
    "Here we will further inspect the relationship between features and our target variable (\"Weekly_Sales\"), and features that are highly correlated between each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-junction",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8737,
     "status": "ok",
     "timestamp": 1622683451761,
     "user": {
      "displayName": "Tony Ha",
      "photoUrl": "",
      "userId": "06475472458336290099"
     },
     "user_tz": -120
    },
    "id": "variable-junction",
    "outputId": "0f12d186-faad-4304-8b35-4d4bce2753ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualise a scatter plot in plotly \n",
    "# to see whether there is correlation between Unemployment and Weekly_Sales\n",
    "# since Walmart is a huge retail company that's competitive thanks to cheap prices\n",
    "# but I think Walmart is a default choice for a lot of people who do not know what they want\n",
    "fig = px.scatter(df_total, x=\"Unemployment\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-rates",
   "metadata": {
    "id": "bound-rates"
   },
   "source": [
    "Is there any correlation between the MarkDown1 -5 and Weekly_Sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-broadcasting",
   "metadata": {
    "id": "plastic-broadcasting",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown1\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-roommate",
   "metadata": {
    "id": "premium-roommate",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown2\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-carter",
   "metadata": {
    "id": "intense-carter",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown3\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-electron",
   "metadata": {
    "id": "minor-electron",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown4\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-compatibility",
   "metadata": {
    "id": "protective-compatibility",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown5\", y=\"Weekly_Sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-radical",
   "metadata": {
    "id": "superior-radical",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_total, x=\"MarkDown1\", y=\"MarkDown4\")\n",
    "fig.show()\n",
    "\n",
    "# as we can see there is a positive correlation between MarkDown 1 and Markdown4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-repeat",
   "metadata": {},
   "source": [
    "MarkDown 1-5 do not show strong correlation to Weekly_Sales. Fuel_Price shows strong correlation to Year. We will drop Fuel_Price otherwise they would carry similar information to the model. We won't drop Year as it differentiates the same Weeks for Store and Dept.\n",
    "\n",
    "We can analyze other features that have weak with Weekly_Sales to see if they are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-material",
   "metadata": {
    "id": "acting-material"
   },
   "outputs": [],
   "source": [
    "df_total.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-meter",
   "metadata": {},
   "source": [
    "## Find outliers\n",
    "\n",
    "Let's check for outliers in the features as LinearRegression is very sensitive to outliers.\n",
    "\n",
    "(We could also see them from the scatter matrix that we plotted earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-combining",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "incorporated-combining",
    "outputId": "f169631a-c47e-4c0a-a640-5652aa146797",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot a histogram to check frequency distribution and spot outliers\n",
    "\n",
    "df_total.hist(figsize=(20,30), xrot=45, bins=50)\n",
    "plt.show()\n",
    "\n",
    "# Temperature is left-skewed (negative skewness)\n",
    "# MarkDown1-5 heavily imbalanced - perform imputation and apply logarithmic transformation (if there is time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-tsunami",
   "metadata": {
    "id": "chemical-tsunami",
    "outputId": "49b86f3b-b900-4d22-fe66-c3c5f676d68a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot histogram with plotly\n",
    "#x1 = df_total[\"Store\"]\n",
    "#x2 = df_total[\"Temperature\"]\n",
    "#x3 = df_total[\"Fuel_Price\"]\n",
    "\n",
    "#x4 = df_total[\"MarkDown1\"]\n",
    "#x5 = df_total[\"MarkDown2\"]\n",
    "#x6 = df_total[\"MarkDown3\"]\n",
    "#x7 = df_total[\"MarkDown4\"]\n",
    "#x8 = df_total[\"MarkDown5\"]\n",
    "\n",
    "#x9 = df_total[\"CPI\"]\n",
    "#x10 = df_total[\"Unemployment\"]\n",
    "#x11 = df_total[\"IsHoliday\"]\n",
    "#x12 = df_total[\"Type\"]\n",
    "#x13 = df_total[\"Size\"]\n",
    "# x14 = df_total[\"Dept\"]\n",
    "\n",
    "# x15 = df_total[\"Weekly_Sales\"]\n",
    "# x16 = df_total[\"Month\"]\n",
    "# x17 = df_total[\"Week\"]\n",
    "# x18 = df_total[\"Year\"]\n",
    "\n",
    "# hist_data = [x1, x2, x3,x4, x5, x6, x7, x8, x9,x10, x11, x12,x13, x14, x15,x16, x17, x18]\n",
    "\n",
    "# group_labels = ['Store', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
    "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
    "       'IsHoliday', 'Type', 'Size', 'Dept', 'Weekly_Sales', 'Month', 'Week',\n",
    "       'Year']\n",
    "\n",
    "# colors = ['#333F44', '#37AA9C', '#94F3E4', '#660000','#663300','#666600','#333300','#000000','#FF0000','#800000','#FFFF00',\n",
    "          '#808000','#00FF00', '#00FFFF','#008080','#0000FF', '#000080', '#FF00FF']\n",
    "\n",
    "\n",
    "# Create distplot with curve_type set to 'normal'\n",
    "#fig = ff.create_distplot(hist_data, group_labels, show_hist=False, colors=colors)\n",
    "\n",
    "# Add title\n",
    "#fig.update_layout(title_text='Curve and Rug Plot')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-portuguese",
   "metadata": {
    "id": "peaceful-portuguese",
    "outputId": "f49775b6-6ada-441b-b562-9f1a33b90fb4"
   },
   "outputs": [],
   "source": [
    "fig = px.box(df_total, y=\"Temperature\")\n",
    "fig.show()\n",
    "\n",
    "# Temperature has an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-cardiff",
   "metadata": {
    "id": "reasonable-cardiff",
    "outputId": "c13279d3-07f3-4005-d520-064e61adda5f"
   },
   "outputs": [],
   "source": [
    "fig = px.box(df_total, y=\"Unemployment\")\n",
    "fig.show()\n",
    "\n",
    "# Unemployment has outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-sculpture",
   "metadata": {
    "id": "great-sculpture",
    "outputId": "15bd2caa-2d10-4f3c-e513-13877fd29f3c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.box(df_total, y=\"Fuel_Price\")\n",
    "fig.show()\n",
    "\n",
    "# Fuel Price has no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "discrete-offset",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-quantum",
   "metadata": {
    "id": "pending-quantum"
   },
   "source": [
    "## Objective\n",
    "\n",
    "Choose the target variable y, and predict from features x. We want to fit a straight line to this data that minimizes the average squared distance between the data sample points and the fitted line. We can use the intercept and slope (which are coefficients) learned from this data to predict y (in this case Weekly Sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-retailer",
   "metadata": {
    "id": "satisfied-retailer",
    "outputId": "a825142d-c0e4-4827-8534-c55c0147a7f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# review data again to identify which label we want to predict\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-initial",
   "metadata": {
    "id": "subtle-initial",
    "outputId": "c6333a7d-93cf-40b2-a7a4-d490610d86b5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first, we need to defined the target (dependent) variable we seek to predict\n",
    "# we want to predict Weekly_Sales, isolate the y variable\n",
    "y = df_total[\"Weekly_Sales\"]\n",
    "\n",
    "# then we drop the y variable from the features (X)\n",
    "X = df_total.drop([\"Weekly_Sales\"], axis=1)\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=47)\n",
    "print(f\"Length of train data: {len(X_train)}\")\n",
    "print(f\"Length of test data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-selection",
   "metadata": {
    "id": "cellular-selection",
    "outputId": "66c27bdd-04fc-4303-fb2e-57fe7d6533f3"
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-manitoba",
   "metadata": {
    "id": "brilliant-manitoba"
   },
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# import evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# define the regression model\n",
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-uganda",
   "metadata": {
    "id": "opened-uganda",
    "outputId": "3239eb0c-3a53-444d-e451-30b816abb1ba"
   },
   "outputs": [],
   "source": [
    "# next, we fit the model to our data\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# then calculate a score\n",
    "\n",
    "lm.score(X_train,y_train) # the coefficient of determination R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-schedule",
   "metadata": {
    "id": "funky-schedule",
    "outputId": "37c4e0b7-ed66-465f-d0fd-da8a3b38cd8c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-province",
   "metadata": {},
   "source": [
    "## Interpret the Coefficients\n",
    "\n",
    "The coefficients(b0 and b1) will allow us to model our equation with values and find the best fit line. The linear_regressor variable (assigned to a LinearRegression object), is able to have the intercept and coefficients extracted, using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints y-intercept\n",
    "print(lm.intercept_)\n",
    "\n",
    "# prints the coefficient\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-bottle",
   "metadata": {},
   "source": [
    "## Making predictions based on our model\n",
    "\n",
    "Now that we have trained our algorithm, itâ€™s time to make some predictions. To do so, we will use our test data and see how accurately our algorithm predicts the Weekly Sales.\n",
    "\n",
    "Making predictions based on our model, we will use the code below to pass the predict method to our test data. This will return predicted values of target y given the new test X data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-germany",
   "metadata": {
    "id": "sexual-germany",
    "outputId": "1ec0646c-7f28-4003-aef4-c1839e829128",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we have the first imperfect iteration (It1)\n",
    "# y_pred is prediction of y\n",
    "\n",
    "y_pred= lm.predict(X_test) # make predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-poverty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the shape of the training and testing data\n",
    "print(X_test.shape, y_test.shape, X_train.shape, y_train.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-latex",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "There are three primary metrics used to evaluate linear models. These are: Mean absolute error (MAE), Mean squared error (MSE), or Root mean squared error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-latvia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "# print result of MAE\n",
    "print(metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "#print result of MSE\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#print result of RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-momentum",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The model is not performing well, because we ran a Simple Linear Regression, which operates in 2 dimensions. The dataset is too large and has multiple dimensions.\n",
    "\n",
    "So we will try to run Multiple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-morning",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-broadway",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "We want to predict Weekly Sales based on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of a df_total\n",
    "\n",
    "df2_total = df_total.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop MarkDown 4 and Fuel_Price \n",
    "df2_total = df2_total.drop([\"MarkDown4\", \"Fuel_Price\"], axis=1)\n",
    "df2_total.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-walnut",
   "metadata": {},
   "source": [
    "## Normalize Data For Comparison\n",
    "\n",
    "We need to scale the data to the range of 0 to 1. We will use MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-rental",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale and plot the features against Weekly_Sales (target) using the MinMax scaler (Normalization)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "col_name = df2_total.drop('Weekly_Sales', axis = 1).columns[:]\n",
    "x = df2_total.loc[:, col_name]\n",
    "y = df2_total['Weekly_Sales']\n",
    "\n",
    "# Normalizing x\n",
    "x = pd.DataFrame(data = min_max_scaler.fit_transform(x), columns = col_name)\n",
    "\n",
    "# Examine the normalized data\n",
    "print(df2_total.head())\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-yacht",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run df_total for comparison\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-negotiation",
   "metadata": {},
   "source": [
    "Now, we would like to examine the relationship of each feature against the target (price). We can do this through sns.regplot(). regplot() will also try to draw a best fit line to show the linear relationship between each feature and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-conservative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot heatmap to visualize the data after normalisation\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "sns.heatmap(df2_total.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-disposition",
   "metadata": {},
   "source": [
    "Now we will split the dataset into training set and testing set.\n",
    "We usually use 60 -80 % for training and 20 - 40 % for testing.\n",
    "\n",
    "X is the input dataset to the model\n",
    "y is the output dataset to the model\n",
    "test_size: the percent of data that we want to use for testing, usually from (0.2 - 0.4)\n",
    "random_state: randomly split the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-casino",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop the y variable from the features (X)\n",
    "X = df2_total.drop('Weekly_Sales', axis = 1)\n",
    "# we want to predict Weekly_Sales, isolate the y variable \n",
    "y = df2_total['Weekly_Sales']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=47)\n",
    "print(\"Train features shape : \", X_train.shape)\n",
    "print(\"Train target shape   : \", y_train.shape)\n",
    "print(\"Test features shape  : \", X_test.shape)\n",
    "print(\"Test target shape    : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-jacket",
   "metadata": {},
   "source": [
    "## Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = LinearRegression(normalize = True) # the parameter normalized = True enables the data to be normalized when fed into the model\n",
    "# fit the training data into the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-advocacy",
   "metadata": {},
   "source": [
    "## Interpret The Model\n",
    "\n",
    "We generated a LinearRegression model that consist of coefficients and intercept. We can now have a look at the intercept and coefficients for our model and interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-remark",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Model intercept  : \", model.intercept_, \"\\n\")\n",
    "print(\"Model coefficient: \", model.coef_, \"\\n\")\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    print(X.columns[i], \": \", model.coef_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-compilation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model evaluation for training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Examine the first 10 predicted output from the model\n",
    "output = pd.DataFrame(y_train[0:15])\n",
    "output['Predicted'] = y_train_pred[0:15]\n",
    "output['Difference'] = output['Predicted'] - output['Weekly_Sales']\n",
    "print(output, \"\\n\")\n",
    "\n",
    "print(\"Model training performance:\")\n",
    "print(\"---------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Model evaluation for testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "output = pd.DataFrame(y_test[0:15])\n",
    "output['Predicted'] = y_test_pred[0:15]\n",
    "output['Difference'] = output['Predicted'] - output['Weekly_Sales']\n",
    "print(output, \"\\n\")\n",
    "\n",
    "print(\"Model testing performance:\")\n",
    "print(\"--------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-utilization",
   "metadata": {},
   "source": [
    "The r2 score of our model is just 0.069 and the difference between the actual and predicted value is high.\n",
    "\n",
    "Why is this happening?\n",
    "\n",
    "- The features have no linear relationship with Weekly_Sales.\n",
    "- Features need to be further cleaned and engineered.\n",
    "\n",
    "How to solve it?\n",
    "\n",
    "- Clean the outliers and invalid data.\n",
    "- Try out other models such as DecisionTreeRegressor and GradientBoostingRegressor.\n",
    "\n",
    "- These models can be found in the scikit-learn documentation. With that, we need to examine their r2 score, MSE, RMSE and MAE and compare it with LinearRegression model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "final_project9_version-4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
